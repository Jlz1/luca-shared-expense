{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147b74f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpaddleocr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaddleOCR\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddleocr\\__init__.py:15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) 2025 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpaddlex\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbenchmark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m benchmark\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     ChartParsing,\n\u001b[32m     19\u001b[39m     DocImgOrientationClassification,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     TextRecognition,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     DocPreprocessor,\n\u001b[32m     34\u001b[39m     DocUnderstanding,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     TableRecognitionPipelineV2,\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\__init__.py:49\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m     46\u001b[39m __version__ = version.get_pdx_version()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pipeline, create_predictor\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_model\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_dataset_checker, build_evaluator, build_trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\inference\\__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_predictor\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pipeline, load_pipeline_config\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhpi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HPIConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\inference\\models\\__init__.py:26\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mofficial_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m official_models\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# from .table_recognition import TablePredictor\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# from .general_recognition import ShiTuRecPredictor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01manomaly_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UadPredictor\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasePredictor\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenAIConfig, need_local_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\inference\\models\\anomaly_detection\\__init__.py:15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredictor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UadPredictor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\inference\\models\\anomaly_detection\\predictor.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Tuple, Union\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manomaly_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODELS\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunc_register\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FuncRegister\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_sampler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageBatchSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\modules\\__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_module\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01manomaly_detection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UadDatasetChecker, UadEvaluator, UadExportor, UadTrainer\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_dataset_checker, build_evaluator, build_exportor, build_trainer\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mface_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     FaceRecDatasetChecker,\n\u001b[32m     20\u001b[39m     FaceRecEvaluator,\n\u001b[32m     21\u001b[39m     FaceRecExportor,\n\u001b[32m     22\u001b[39m     FaceRecTrainer,\n\u001b[32m     23\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\modules\\anomaly_detection\\__init__.py:15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_checker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UadDatasetChecker\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UadEvaluator\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexportor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UadExportor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\modules\\anomaly_detection\\dataset_checker\\__init__.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDatasetChecker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODELS\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_src\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m anaylse_dataset, check_dataset, convert_dataset, split_dataset\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mUadDatasetChecker\u001b[39;00m(BaseDatasetChecker):\n\u001b[32m     25\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Dataset Checker for Semantic Segmentation Model\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\modules\\anomaly_detection\\dataset_checker\\dataset_src\\__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalyse_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m anaylse_dataset\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheck_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_dataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvert_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\paddlex\\modules\\anomaly_detection\\dataset_checker\\dataset_src\\analyse_dataset.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_open\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dep_available(\u001b[33m\"\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;129m@function_requires_deps\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manaylse_dataset\u001b[39m(dataset_dir, output):\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"class analysis for dataset\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1299\u001b[39m\n\u001b[32m   1295\u001b[39m     rcParams[\u001b[33m'\u001b[39m\u001b[33mbackend_fallback\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m'\u001b[39m\u001b[33mMPLBACKEND\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     \u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = os.environ.get(\u001b[33m'\u001b[39m\u001b[33mMPLBACKEND\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_backend\u001b[39m(*, auto_select=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1303\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1304\u001b[39m \u001b[33;03m    Return the name of the current backend.\u001b[39;00m\n\u001b[32m   1305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m \u001b[33;03m    matplotlib.use\u001b[39;00m\n\u001b[32m   1324\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:772\u001b[39m, in \u001b[36mRcParams.__setitem__\u001b[39m\u001b[34m(self, key, val)\u001b[39m\n\u001b[32m    770\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m     cval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:273\u001b[39m, in \u001b[36mvalidate_backend\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_backend\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m _auto_backend_sentinel \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_valid_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m s\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\backends\\registry.py:244\u001b[39m, in \u001b[36mBackendRegistry.is_valid_backend\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Only load entry points if really need to and not already done so.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_entry_points_loaded\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend_to_gui_framework:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\backends\\registry.py:116\u001b[39m, in \u001b[36mBackendRegistry._ensure_entry_points_loaded\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ensure_entry_points_loaded\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Load entry points, if they have not already been loaded.\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._loaded_entry_points:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         entries = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_entry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_and_store_entry_points(entries)\n\u001b[32m    118\u001b[39m         \u001b[38;5;28mself\u001b[39m._loaded_entry_points = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\backends\\registry.py:155\u001b[39m, in \u001b[36mBackendRegistry._read_entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    153\u001b[39m names = [entry[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries]\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minline\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[43mbackward_compatible_entry_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmatplotlib_inline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmatplotlib_inline.backend_inline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mipympl\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[32m    159\u001b[39m     backward_compatible_entry_points(\n\u001b[32m    160\u001b[39m         entries, \u001b[33m\"\u001b[39m\u001b[33mipympl\u001b[39m\u001b[33m\"\u001b[39m, (\u001b[32m0\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m4\u001b[39m), [\u001b[33m\"\u001b[39m\u001b[33mipympl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwidget\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mipympl.backend_nbagg\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\backends\\registry.py:147\u001b[39m, in \u001b[36mBackendRegistry._read_entry_points.<locals>.backward_compatible_entry_points\u001b[39m\u001b[34m(entries, module_name, threshold_version, names, target)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    146\u001b[39m     module_version = im.version(module_name)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_parse_to_version_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_version\u001b[49m\u001b[43m)\u001b[49m < threshold_version:\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[32m    149\u001b[39m             entries.append((name, target))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:196\u001b[39m, in \u001b[36m_parse_to_version_info\u001b[39m\u001b[34m(version_str)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_to_version_info\u001b[39m(version_str):\n\u001b[32m    189\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03m    Parse a version string to a namedtuple analogous to sys.version_info.\u001b[39;00m\n\u001b[32m    191\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \u001b[33;03m    https://docs.python.org/3/library/sys.html#sys.version_info\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     v = \u001b[43mparse_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m v.pre \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m v.post \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m v.dev \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _VersionInfo(v.major, v.minor, v.micro, \u001b[33m'\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\packaging\\version.py:56\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(version)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(version: \u001b[38;5;28mstr\u001b[39m) -> Version:\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the given version string.\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m \u001b[33;03m    >>> parse('1.0.dev1')\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33;03m    :raises InvalidVersion: When the version string is not a valid version.\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jerem\\anaconda3\\Lib\\site-packages\\packaging\\version.py:200\u001b[39m, in \u001b[36mVersion.__init__\u001b[39m\u001b[34m(self, version)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize a Version object.\u001b[39;00m\n\u001b[32m    190\u001b[39m \n\u001b[32m    191\u001b[39m \u001b[33;03m:param version:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m \u001b[33;03m    exception will be raised.\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# Validate the version and parse it into pieces\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m match = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_regex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidVersion(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'NoneType'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import difflib\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ocr_engine = PaddleOCR(use_textline_orientation=True, lang='en')\n",
    "\n",
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):\n",
    "    \"\"\"Mempertajam citra untuk mengatasi blur akibat kertas melengkung\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
    "    sharpened = np.maximum(sharpened, 0)\n",
    "    sharpened = np.minimum(sharpened, 255)\n",
    "    return sharpened.astype(np.uint8)\n",
    "\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([[0, 0],[maxWidth - 1, 0],[maxWidth - 1, maxHeight - 1],[0, maxHeight - 1]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    return cv2.warpPerspective(image, M, (maxWidth, maxHeight), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "def safe_crop_with_padding(image, x, y, w, h, padding_pct=0.1):\n",
    "    h_img, w_img = image.shape[:2]\n",
    "    pad_w = int(w * padding_pct); pad_h = int(h * padding_pct)\n",
    "    x1 = max(0, x - pad_w); y1 = max(0, y - pad_h)\n",
    "    x2 = min(w_img, x + w + pad_w); y2 = min(h_img, y + h + pad_h)\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def auto_scan_document(image):\n",
    "    orig = image.copy()\n",
    "    ratio = image.shape[0] / 500.0\n",
    "    h = 500\n",
    "    w = int(image.shape[1] / ratio)\n",
    "    small_img = cv2.resize(image, (w, h))\n",
    "    total_area = h * w\n",
    "    gray = cv2.cvtColor(small_img, cv2.COLOR_BGR2GRAY) if len(small_img.shape) == 3 else small_img\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    screenCnt = None; largest_contour = None; max_area = 0\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > max_area: max_area = area; largest_contour = c\n",
    "        if area < (total_area * 0.05): continue\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4: screenCnt = approx; break\n",
    "\n",
    "    if screenCnt is not None:\n",
    "        pts = screenCnt.reshape(4, 2) * ratio\n",
    "        return four_point_transform(orig, pts), True\n",
    "    elif largest_contour is not None and max_area > (total_area * 0.1):\n",
    "        x, y, w_box, h_box = cv2.boundingRect(largest_contour)\n",
    "        x = int(x * ratio); y = int(y * ratio); w_box = int(w_box * ratio); h_box = int(h_box * ratio)\n",
    "        return safe_crop_with_padding(orig, x, y, w_box, h_box, padding_pct=0.1), False\n",
    "    else:\n",
    "        h_orig, w_orig = orig.shape[:2]\n",
    "        crop_h, crop_w = int(h_orig * 0.7), int(w_orig * 0.7)\n",
    "        y1 = (h_orig - crop_h)//2; x1 = (w_orig - crop_w)//2\n",
    "        return orig[y1:y1+crop_h, x1:x1+crop_w], False\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos = np.abs(M[0, 0]); sin = np.abs(M[0, 1])\n",
    "    nW = int((h * sin) + (w * cos)); nH = int((h * cos) + (w * sin))\n",
    "    M[0, 2] += (nW / 2) - cX; M[1, 2] += (nH / 2) - cY\n",
    "    return cv2.warpAffine(image, M, (nW, nH), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "def detect_orientation_and_deskew(image):\n",
    "    img_padded = cv2.copyMakeBorder(image, 20, 20, 20, 20, cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "    gray = cv2.cvtColor(img_padded, cv2.COLOR_BGR2GRAY) if len(img_padded.shape) == 3 else img_padded\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 25, 15)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    horizontal_votes = 0; vertical_votes = 0; angles = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < 100 or area > (image.shape[0] * image.shape[1] * 0.5): continue\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        (center, (w, h), angle) = rect\n",
    "        if w < h: w, h = h, w; angle += 90\n",
    "        aspect_ratio = w / float(h) if h > 0 else 0\n",
    "        if aspect_ratio > 2.0:\n",
    "            horizontal_votes += 1\n",
    "            if angle > 45: angle -= 90\n",
    "            elif angle < -45: angle += 90\n",
    "            angles.append(angle)\n",
    "        elif aspect_ratio < 0.5: vertical_votes += 1\n",
    "\n",
    "    if vertical_votes > horizontal_votes * 1.5:\n",
    "        return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    else:\n",
    "        if len(angles) > 5:\n",
    "            median = np.median(angles)\n",
    "            if abs(median) > 20 or abs(median) < 0.5: return image\n",
    "            return rotate_image(image, median)\n",
    "        return image\n",
    "\n",
    "def tuning_lab(image, blur_kernel=21, denoise_h=10, upscale=False):\n",
    "    if image is None: return None\n",
    "    processed_img, success = auto_scan_document(image)\n",
    "    processed_img = detect_orientation_and_deskew(processed_img)\n",
    "    if upscale:\n",
    "        processed_img = cv2.resize(processed_img, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "    processed_img = unsharp_mask(processed_img, amount=1.5)\n",
    "\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "# --- 3. CLEANING & IMPROVED GROUPING LOGIC ---\n",
    "\n",
    "def apply_spell_correction(text_line):\n",
    "    RECEIPT_KEYWORDS = [\"TOTAL\", \"SUBTOTAL\", \"CASH\", \"CHANGE\", \"PAYMENT\", \"TAX\", \"PAJAK\", \"PPN\", \"HARGA\", \"QTY\", \"RECEIPT\", \"STRUK\", \"TUNAI\", \"DISKON\"]\n",
    "    words = text_line.split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        clean_word = ''.join(e for e in word if e.isalnum())\n",
    "        if len(clean_word) < 3: corrected_words.append(word); continue\n",
    "        matches = difflib.get_close_matches(clean_word.upper(), RECEIPT_KEYWORDS, n=1, cutoff=0.75)\n",
    "        corrected_words.append(matches[0] if matches else word)\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def cleanup_text_spacing(text):\n",
    "    text = re.sub(r'(\\d)\\s*([.,])\\s*(\\d)', r'\\1\\2\\3', text)\n",
    "    text = re.sub(r'(@)\\s+(\\d)', r'\\1\\2', text)\n",
    "    text = re.sub(r'(Rp)\\s+(\\d)', r'\\1\\2', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def group_lines_by_height_overlap(results, overlap_threshold=0.5):\n",
    "    if not results: return \"\"\n",
    "\n",
    "    results = sorted(results, key=lambda r: r[0][0][1])\n",
    "\n",
    "    lines = [] \n",
    "\n",
    "    while results:\n",
    "        current_item = results.pop(0)\n",
    "        box_curr = current_item[0]\n",
    "\n",
    "        y_min_curr = min(box_curr[0][1], box_curr[1][1])\n",
    "        y_max_curr = max(box_curr[2][1], box_curr[3][1])\n",
    "        height_curr = y_max_curr - y_min_curr\n",
    "\n",
    "        current_line = [current_item]\n",
    "        remaining_results = []\n",
    "\n",
    "        for other_item in results:\n",
    "            box_other = other_item[0]\n",
    "            y_min_other = min(box_other[0][1], box_other[1][1])\n",
    "            y_max_other = max(box_other[2][1], box_other[3][1])\n",
    "\n",
    "            # Hitung Overlap Vertical\n",
    "            overlap_min = max(y_min_curr, y_min_other)\n",
    "            overlap_max = min(y_max_curr, y_max_other)\n",
    "            overlap_h = max(0, overlap_max - overlap_min)\n",
    "\n",
    "            height_other = y_max_other - y_min_other\n",
    "            min_height = min(height_curr, height_other)\n",
    "\n",
    "            # Jika overlap lebih dari 50% dari tinggi teks terkecil, anggap satu baris\n",
    "            if min_height > 0 and (overlap_h / min_height) > overlap_threshold:\n",
    "                current_line.append(other_item)\n",
    "            else:\n",
    "                remaining_results.append(other_item)\n",
    "\n",
    "        # Update results dengan sisa item yang belum masuk baris manapun\n",
    "        results = remaining_results\n",
    "\n",
    "        # Sort item dalam satu baris berdasarkan koordinat X (kiri ke kanan)\n",
    "        current_line.sort(key=lambda item: item[0][0][0])\n",
    "        lines.append(current_line)\n",
    "\n",
    "    # Gabungkan text menjadi string\n",
    "    final_text_lines = []\n",
    "    for line_items in lines:\n",
    "        # Gabungkan kata dalam satu baris\n",
    "        # Cek jarak horizontal. Jika jauh, tambah spasi ekstra/tab biar rapi\n",
    "        line_str = \"\"\n",
    "        for i, item in enumerate(line_items):\n",
    "            text = item[1]\n",
    "            if i > 0:\n",
    "                # Hitung jarak X dari item sebelumnya\n",
    "                prev_box = line_items[i-1][0]\n",
    "                curr_box = item[0]\n",
    "                prev_x_end = max(prev_box[1][0], prev_box[2][0])\n",
    "                curr_x_start = min(curr_box[0][0], curr_box[3][0])\n",
    "                distance = curr_x_start - prev_x_end\n",
    "\n",
    "                # Jika jaraknya agak jauh (> 20 pixel), kasih spasi lebih banyak\n",
    "                if distance > 20:\n",
    "                    line_str += \" \\t \" + text\n",
    "                else:\n",
    "                    line_str += \" \" + text\n",
    "            else:\n",
    "                line_str += text\n",
    "\n",
    "        # Bersihkan string\n",
    "        clean_line = cleanup_text_spacing(apply_spell_correction(line_str))\n",
    "        final_text_lines.append(clean_line)\n",
    "\n",
    "    return \"\\n\".join(final_text_lines)\n",
    "\n",
    "# --- 3.5. SMART FILTER FUNCTION (UPDATED) ---\n",
    "def smart_filter_receipt(text, context_window=1):\n",
    "    \"\"\"\n",
    "    Filter OCR text to keep only transaction-relevant lines with context.\n",
    "    \"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # === STRATEGY 1: BLACKLIST PATTERNS ===\n",
    "    blacklist_patterns = [\n",
    "        r'No\\s*[:.]?\\s*[A-Z0-9]{10,}',\n",
    "        r'\\d{2}[-./]\\d{2}[-./]\\d{2,4}',\n",
    "        r'Tanggal\\s*:', r'Info\\s*:', r'Mode\\s*:', r'Table\\s*:?', r'Bill\\s*:',\n",
    "        r'Receipt\\s*:', r'[A-Z\\s]{5,}\\d{5,}', r'/\\d+\\.\\d+\\.\\d+/',\n",
    "        r'[A-Z]{2,}\\d{2,4}-\\d{4,}', r'Phone|Fax|Email|Website',\n",
    "        r'Welcome|Thank|Terima',\n",
    "    ]\n",
    "    blacklist_compiled = [re.compile(pattern, re.IGNORECASE) for pattern in blacklist_patterns]\n",
    "\n",
    "    # === STRATEGY 2: STRONG MONEY PATTERN ===\n",
    "    strong_money_patterns = [\n",
    "        r'(?:Rp\\.?\\s*|@\\s*)\\d[\\d.,]+',\n",
    "        r'\\b\\d{1,3}[.,]\\d{3}(?:[.,]\\d{3})*\\b',\n",
    "        r'^\\s*\\d{3,}\\s*$'\n",
    "    ]\n",
    "    strong_money_compiled = [re.compile(p, re.IGNORECASE) for p in strong_money_patterns]\n",
    "\n",
    "    # === STRATEGY 3: TRANSACTION KEYWORDS ===\n",
    "    keywords = [\n",
    "        'total', 'subtotal', 'tax', 'pajak', 'ppn', 'cash', 'tunai',\n",
    "        'change', 'kembalian', 'payment', 'bayar', 'diskon', 'discount',\n",
    "        'harga', 'price', 'qty', 'jumlah', 'item', 'grand', 'service',\n",
    "        'dana', 'qris', 'gopay', 'debit', 'credit', 'card', 'paid'\n",
    "    ]\n",
    "    keyword_pattern = re.compile(r'\\b(' + '|'.join(keywords) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    relevant_indices = set()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line_stripped = line.strip()\n",
    "        if not line_stripped: continue\n",
    "\n",
    "        is_blacklisted = any(pattern.search(line_stripped) for pattern in blacklist_compiled)\n",
    "        if is_blacklisted: continue\n",
    "\n",
    "        has_keyword = keyword_pattern.search(line_stripped)\n",
    "        has_strong_money = any(pattern.search(line_stripped) for pattern in strong_money_compiled)\n",
    "\n",
    "        if has_keyword or has_strong_money:\n",
    "            relevant_indices.add(i)\n",
    "            for j in range(max(0, i - context_window), i): relevant_indices.add(j)\n",
    "            for j in range(i + 1, min(len(lines), i + context_window + 1)): relevant_indices.add(j)\n",
    "\n",
    "    if not relevant_indices:\n",
    "        return \"[Tidak ada transaksi terdeteksi]\"\n",
    "\n",
    "    sorted_indices = sorted(relevant_indices)\n",
    "    filtered_lines = [lines[i] for i in sorted_indices]\n",
    "    return '\\n'.join(filtered_lines)\n",
    "\n",
    "# --- 4. MAIN BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 1. Tentukan Folder Target\n",
    "    current_dir = os.getcwd()\n",
    "    folder_path = os.path.join(current_dir, \"..\", \"..\", \"dataset\", \"test\", \"img\")\n",
    "    print(f\"üìÇ Membaca semua gambar dari folder: {folder_path}\")\n",
    "\n",
    "    # 2. Ambil semua file gambar\n",
    "    try:\n",
    "        all_files = os.listdir(folder_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error membaca folder: {e}\")\n",
    "        all_files = []\n",
    "\n",
    "    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def natural_keys(text):\n",
    "        return [int(c) if c.isdigit() else c for c in re.split(r'(\\d+)', text)]\n",
    "    image_files.sort(key=natural_keys)\n",
    "\n",
    "    print(f\"üìä Ditemukan {len(image_files)} gambar siap proses.\\n\")\n",
    "\n",
    "    # 4. Loop Proses\n",
    "    for filename in image_files:\n",
    "        if \"sample\" in filename: continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"üöÄ Memproses: {filename}\")\n",
    "        print(f\"{'='*40}\")\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                original_img = cv2.imread(img_path)\n",
    "                if original_img is None:\n",
    "                    print(\"‚ùå Gambar corrupt/rusak.\")\n",
    "                    continue\n",
    "\n",
    "                # A. Tuning\n",
    "                result_image = tuning_lab(original_img, denoise_h=10, upscale=True)\n",
    "\n",
    "                if result_image is not None:\n",
    "                    # B. OCR\n",
    "                    paddle_raw_result = ocr_engine.ocr(result_image)\n",
    "\n",
    "                    # C. Parsing (Format Data)\n",
    "                    formatted_results = []\n",
    "                    if paddle_raw_result:\n",
    "                        first_data = paddle_raw_result[0]\n",
    "                        if isinstance(first_data, list):\n",
    "                            source = paddle_raw_result[0] if len(paddle_raw_result) > 0 and isinstance(paddle_raw_result[0], list) else paddle_raw_result\n",
    "                            for line in source:\n",
    "                                try:\n",
    "                                    box = line[0]; txt = line[1][0]; conf = line[1][1]\n",
    "                                    formatted_results.append((box, txt, conf))\n",
    "                                except: continue\n",
    "                        elif isinstance(first_data, dict):\n",
    "                            for item in paddle_raw_result:\n",
    "                                box = item.get('points', []); txt = item.get('text', \"\"); conf = item.get('score', 0)\n",
    "                                formatted_results.append((box, txt, conf))\n",
    "\n",
    "                    # D. Smart Grouping & Filtering\n",
    "                    if formatted_results:\n",
    "                        # 1. Grouping dengan Logic Overlap (Bukan Y biasa)\n",
    "                        full_text = group_lines_by_height_overlap(formatted_results, overlap_threshold=0.5)\n",
    "\n",
    "                        # 2. Filter Transaksi\n",
    "                        filtered_text = smart_filter_receipt(full_text, context_window=1)\n",
    "\n",
    "                        print(\"üìù HASIL TEKS (LAYOUT DIPERBAIKI):\")\n",
    "                        print(filtered_text)\n",
    "                    else:\n",
    "                        print(\"‚ö†Ô∏è Tidak ada teks terbaca.\")\n",
    "                else:\n",
    "                    print(\"‚ùå Gagal Tuning (Preprocessing fail)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error pada file ini: {e}\")\n",
    "        else:\n",
    "            print(\"‚ùå Path tidak valid.\")\n",
    "\n",
    "    print(\"\\n‚úÖ SEMUA FILE SELESAI DIPROSES.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
