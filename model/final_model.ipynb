{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import difflib\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ocr_engine = PaddleOCR(use_textline_orientation=True, lang='en')\n",
    "\n",
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):\n",
    "    \"\"\"Mempertajam citra untuk mengatasi blur akibat kertas melengkung\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
    "    sharpened = np.maximum(sharpened, 0)\n",
    "    sharpened = np.minimum(sharpened, 255)\n",
    "    return sharpened.astype(np.uint8)\n",
    "\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    dst = np.array([[0, 0],[maxWidth - 1, 0],[maxWidth - 1, maxHeight - 1],[0, maxHeight - 1]], dtype=\"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    return cv2.warpPerspective(image, M, (maxWidth, maxHeight), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "def safe_crop_with_padding(image, x, y, w, h, padding_pct=0.1):\n",
    "    h_img, w_img = image.shape[:2]\n",
    "    pad_w = int(w * padding_pct); pad_h = int(h * padding_pct)\n",
    "    x1 = max(0, x - pad_w); y1 = max(0, y - pad_h)\n",
    "    x2 = min(w_img, x + w + pad_w); y2 = min(h_img, y + h + pad_h)\n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "def auto_scan_document(image):\n",
    "    orig = image.copy()\n",
    "    ratio = image.shape[0] / 500.0\n",
    "    h = 500\n",
    "    w = int(image.shape[1] / ratio)\n",
    "    small_img = cv2.resize(image, (w, h))\n",
    "    total_area = h * w\n",
    "    gray = cv2.cvtColor(small_img, cv2.COLOR_BGR2GRAY) if len(small_img.shape) == 3 else small_img\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    screenCnt = None; largest_contour = None; max_area = 0\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > max_area: max_area = area; largest_contour = c\n",
    "        if area < (total_area * 0.05): continue\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4: screenCnt = approx; break\n",
    "\n",
    "    if screenCnt is not None:\n",
    "        pts = screenCnt.reshape(4, 2) * ratio\n",
    "        return four_point_transform(orig, pts), True\n",
    "    elif largest_contour is not None and max_area > (total_area * 0.1):\n",
    "        x, y, w_box, h_box = cv2.boundingRect(largest_contour)\n",
    "        x = int(x * ratio); y = int(y * ratio); w_box = int(w_box * ratio); h_box = int(h_box * ratio)\n",
    "        return safe_crop_with_padding(orig, x, y, w_box, h_box, padding_pct=0.1), False\n",
    "    else:\n",
    "        h_orig, w_orig = orig.shape[:2]\n",
    "        crop_h, crop_w = int(h_orig * 0.7), int(w_orig * 0.7)\n",
    "        y1 = (h_orig - crop_h)//2; x1 = (w_orig - crop_w)//2\n",
    "        return orig[y1:y1+crop_h, x1:x1+crop_w], False\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos = np.abs(M[0, 0]); sin = np.abs(M[0, 1])\n",
    "    nW = int((h * sin) + (w * cos)); nH = int((h * cos) + (w * sin))\n",
    "    M[0, 2] += (nW / 2) - cX; M[1, 2] += (nH / 2) - cY\n",
    "    return cv2.warpAffine(image, M, (nW, nH), borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "\n",
    "def detect_orientation_and_deskew(image):\n",
    "    img_padded = cv2.copyMakeBorder(image, 20, 20, 20, 20, cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "    gray = cv2.cvtColor(img_padded, cv2.COLOR_BGR2GRAY) if len(img_padded.shape) == 3 else img_padded\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 25, 15)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    horizontal_votes = 0; vertical_votes = 0; angles = []\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < 100 or area > (image.shape[0] * image.shape[1] * 0.5): continue\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        (center, (w, h), angle) = rect\n",
    "        if w < h: w, h = h, w; angle += 90\n",
    "        aspect_ratio = w / float(h) if h > 0 else 0\n",
    "        if aspect_ratio > 2.0:\n",
    "            horizontal_votes += 1\n",
    "            if angle > 45: angle -= 90\n",
    "            elif angle < -45: angle += 90\n",
    "            angles.append(angle)\n",
    "        elif aspect_ratio < 0.5: vertical_votes += 1\n",
    "\n",
    "    if vertical_votes > horizontal_votes * 1.5:\n",
    "        return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    else:\n",
    "        if len(angles) > 5:\n",
    "            median = np.median(angles)\n",
    "            if abs(median) > 20 or abs(median) < 0.5: return image\n",
    "            return rotate_image(image, median)\n",
    "        return image\n",
    "\n",
    "def tuning_lab(image, blur_kernel=21, denoise_h=10, upscale=False):\n",
    "    if image is None: return None\n",
    "    processed_img, success = auto_scan_document(image)\n",
    "    processed_img = detect_orientation_and_deskew(processed_img)\n",
    "    if upscale:\n",
    "        processed_img = cv2.resize(processed_img, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "    processed_img = unsharp_mask(processed_img, amount=1.5)\n",
    "\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "# --- 3. CLEANING & IMPROVED GROUPING LOGIC ---\n",
    "\n",
    "def apply_spell_correction(text_line):\n",
    "    RECEIPT_KEYWORDS = [\"TOTAL\", \"SUBTOTAL\", \"CASH\", \"CHANGE\", \"PAYMENT\", \"TAX\", \"PAJAK\", \"PPN\", \"HARGA\", \"QTY\", \"RECEIPT\", \"STRUK\", \"TUNAI\", \"DISKON\"]\n",
    "    words = text_line.split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        clean_word = ''.join(e for e in word if e.isalnum())\n",
    "        if len(clean_word) < 3: corrected_words.append(word); continue\n",
    "        matches = difflib.get_close_matches(clean_word.upper(), RECEIPT_KEYWORDS, n=1, cutoff=0.75)\n",
    "        corrected_words.append(matches[0] if matches else word)\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def cleanup_text_spacing(text):\n",
    "    text = re.sub(r'(\\d)\\s*([.,])\\s*(\\d)', r'\\1\\2\\3', text)\n",
    "    text = re.sub(r'(@)\\s+(\\d)', r'\\1\\2', text)\n",
    "    text = re.sub(r'(Rp)\\s+(\\d)', r'\\1\\2', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def group_lines_by_height_overlap(results, overlap_threshold=0.5):\n",
    "    if not results: return \"\"\n",
    "\n",
    "    results = sorted(results, key=lambda r: r[0][0][1])\n",
    "\n",
    "    lines = [] \n",
    "\n",
    "    while results:\n",
    "        current_item = results.pop(0)\n",
    "        box_curr = current_item[0]\n",
    "\n",
    "        y_min_curr = min(box_curr[0][1], box_curr[1][1])\n",
    "        y_max_curr = max(box_curr[2][1], box_curr[3][1])\n",
    "        height_curr = y_max_curr - y_min_curr\n",
    "\n",
    "        current_line = [current_item]\n",
    "        remaining_results = []\n",
    "\n",
    "        for other_item in results:\n",
    "            box_other = other_item[0]\n",
    "            y_min_other = min(box_other[0][1], box_other[1][1])\n",
    "            y_max_other = max(box_other[2][1], box_other[3][1])\n",
    "\n",
    "            # Hitung Overlap Vertical\n",
    "            overlap_min = max(y_min_curr, y_min_other)\n",
    "            overlap_max = min(y_max_curr, y_max_other)\n",
    "            overlap_h = max(0, overlap_max - overlap_min)\n",
    "\n",
    "            height_other = y_max_other - y_min_other\n",
    "            min_height = min(height_curr, height_other)\n",
    "\n",
    "            # Jika overlap lebih dari 50% dari tinggi teks terkecil, anggap satu baris\n",
    "            if min_height > 0 and (overlap_h / min_height) > overlap_threshold:\n",
    "                current_line.append(other_item)\n",
    "            else:\n",
    "                remaining_results.append(other_item)\n",
    "\n",
    "        # Update results dengan sisa item yang belum masuk baris manapun\n",
    "        results = remaining_results\n",
    "\n",
    "        # Sort item dalam satu baris berdasarkan koordinat X (kiri ke kanan)\n",
    "        current_line.sort(key=lambda item: item[0][0][0])\n",
    "        lines.append(current_line)\n",
    "\n",
    "    # Gabungkan text menjadi string\n",
    "    final_text_lines = []\n",
    "    for line_items in lines:\n",
    "        # Gabungkan kata dalam satu baris\n",
    "        # Cek jarak horizontal. Jika jauh, tambah spasi ekstra/tab biar rapi\n",
    "        line_str = \"\"\n",
    "        for i, item in enumerate(line_items):\n",
    "            text = item[1]\n",
    "            if i > 0:\n",
    "                # Hitung jarak X dari item sebelumnya\n",
    "                prev_box = line_items[i-1][0]\n",
    "                curr_box = item[0]\n",
    "                prev_x_end = max(prev_box[1][0], prev_box[2][0])\n",
    "                curr_x_start = min(curr_box[0][0], curr_box[3][0])\n",
    "                distance = curr_x_start - prev_x_end\n",
    "\n",
    "                # Jika jaraknya agak jauh (> 20 pixel), kasih spasi lebih banyak\n",
    "                if distance > 20:\n",
    "                    line_str += \" \\t \" + text\n",
    "                else:\n",
    "                    line_str += \" \" + text\n",
    "            else:\n",
    "                line_str += text\n",
    "\n",
    "        # Bersihkan string\n",
    "        clean_line = cleanup_text_spacing(apply_spell_correction(line_str))\n",
    "        final_text_lines.append(clean_line)\n",
    "\n",
    "    return \"\\n\".join(final_text_lines)\n",
    "\n",
    "# --- 3.5. SMART FILTER FUNCTION (UPDATED) ---\n",
    "def smart_filter_receipt(text, context_window=1):\n",
    "    \"\"\"\n",
    "    Filter OCR text to keep only transaction-relevant lines with context.\n",
    "    \"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # === STRATEGY 1: BLACKLIST PATTERNS ===\n",
    "    blacklist_patterns = [\n",
    "        r'No\\s*[:.]?\\s*[A-Z0-9]{10,}',\n",
    "        r'\\d{2}[-./]\\d{2}[-./]\\d{2,4}',\n",
    "        r'Tanggal\\s*:', r'Info\\s*:', r'Mode\\s*:', r'Table\\s*:?', r'Bill\\s*:',\n",
    "        r'Receipt\\s*:', r'[A-Z\\s]{5,}\\d{5,}', r'/\\d+\\.\\d+\\.\\d+/',\n",
    "        r'[A-Z]{2,}\\d{2,4}-\\d{4,}', r'Phone|Fax|Email|Website',\n",
    "        r'Welcome|Thank|Terima',\n",
    "    ]\n",
    "    blacklist_compiled = [re.compile(pattern, re.IGNORECASE) for pattern in blacklist_patterns]\n",
    "\n",
    "    # === STRATEGY 2: STRONG MONEY PATTERN ===\n",
    "    strong_money_patterns = [\n",
    "        r'(?:Rp\\.?\\s*|@\\s*)\\d[\\d.,]+',\n",
    "        r'\\b\\d{1,3}[.,]\\d{3}(?:[.,]\\d{3})*\\b',\n",
    "        r'^\\s*\\d{3,}\\s*$'\n",
    "    ]\n",
    "    strong_money_compiled = [re.compile(p, re.IGNORECASE) for p in strong_money_patterns]\n",
    "\n",
    "    # === STRATEGY 3: TRANSACTION KEYWORDS ===\n",
    "    keywords = [\n",
    "        'total', 'subtotal', 'tax', 'pajak', 'ppn', 'cash', 'tunai',\n",
    "        'change', 'kembalian', 'payment', 'bayar', 'diskon', 'discount',\n",
    "        'harga', 'price', 'qty', 'jumlah', 'item', 'grand', 'service',\n",
    "        'dana', 'qris', 'gopay', 'debit', 'credit', 'card', 'paid'\n",
    "    ]\n",
    "    keyword_pattern = re.compile(r'\\b(' + '|'.join(keywords) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    relevant_indices = set()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line_stripped = line.strip()\n",
    "        if not line_stripped: continue\n",
    "\n",
    "        is_blacklisted = any(pattern.search(line_stripped) for pattern in blacklist_compiled)\n",
    "        if is_blacklisted: continue\n",
    "\n",
    "        has_keyword = keyword_pattern.search(line_stripped)\n",
    "        has_strong_money = any(pattern.search(line_stripped) for pattern in strong_money_compiled)\n",
    "\n",
    "        if has_keyword or has_strong_money:\n",
    "            relevant_indices.add(i)\n",
    "            for j in range(max(0, i - context_window), i): relevant_indices.add(j)\n",
    "            for j in range(i + 1, min(len(lines), i + context_window + 1)): relevant_indices.add(j)\n",
    "\n",
    "    if not relevant_indices:\n",
    "        return \"[Tidak ada transaksi terdeteksi]\"\n",
    "\n",
    "    sorted_indices = sorted(relevant_indices)\n",
    "    filtered_lines = [lines[i] for i in sorted_indices]\n",
    "    return '\\n'.join(filtered_lines)\n",
    "\n",
    "# --- 4. MAIN BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 1. Tentukan Folder Target\n",
    "    current_dir = os.getcwd()\n",
    "    folder_path = os.path.join(current_dir, \"..\", \"..\", \"dataset\", \"test\", \"img\")\n",
    "    print(f\"üìÇ Membaca semua gambar dari folder: {folder_path}\")\n",
    "\n",
    "    # 2. Ambil semua file gambar\n",
    "    try:\n",
    "        all_files = os.listdir(folder_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error membaca folder: {e}\")\n",
    "        all_files = []\n",
    "\n",
    "    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def natural_keys(text):\n",
    "        return [int(c) if c.isdigit() else c for c in re.split(r'(\\d+)', text)]\n",
    "    image_files.sort(key=natural_keys)\n",
    "\n",
    "    print(f\"üìä Ditemukan {len(image_files)} gambar siap proses.\\n\")\n",
    "\n",
    "    # 4. Loop Proses\n",
    "    for filename in image_files:\n",
    "        if \"sample\" in filename: continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"üöÄ Memproses: {filename}\")\n",
    "        print(f\"{'='*40}\")\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                original_img = cv2.imread(img_path)\n",
    "                if original_img is None:\n",
    "                    print(\"‚ùå Gambar corrupt/rusak.\")\n",
    "                    continue\n",
    "\n",
    "                # A. Tuning\n",
    "                result_image = tuning_lab(original_img, denoise_h=10, upscale=True)\n",
    "\n",
    "                if result_image is not None:\n",
    "                    # B. OCR\n",
    "                    paddle_raw_result = ocr_engine.ocr(result_image)\n",
    "\n",
    "                    # C. Parsing (Format Data)\n",
    "                    formatted_results = []\n",
    "                    if paddle_raw_result:\n",
    "                        first_data = paddle_raw_result[0]\n",
    "                        if isinstance(first_data, list):\n",
    "                            source = paddle_raw_result[0] if len(paddle_raw_result) > 0 and isinstance(paddle_raw_result[0], list) else paddle_raw_result\n",
    "                            for line in source:\n",
    "                                try:\n",
    "                                    box = line[0]; txt = line[1][0]; conf = line[1][1]\n",
    "                                    formatted_results.append((box, txt, conf))\n",
    "                                except: continue\n",
    "                        elif isinstance(first_data, dict):\n",
    "                            for item in paddle_raw_result:\n",
    "                                box = item.get('points', []); txt = item.get('text', \"\"); conf = item.get('score', 0)\n",
    "                                formatted_results.append((box, txt, conf))\n",
    "\n",
    "                    # D. Smart Grouping & Filtering\n",
    "                    if formatted_results:\n",
    "                        # 1. Grouping dengan Logic Overlap (Bukan Y biasa)\n",
    "                        full_text = group_lines_by_height_overlap(formatted_results, overlap_threshold=0.5)\n",
    "\n",
    "                        # 2. Filter Transaksi\n",
    "                        filtered_text = smart_filter_receipt(full_text, context_window=1)\n",
    "\n",
    "                        print(\"üìù HASIL TEKS (LAYOUT DIPERBAIKI):\")\n",
    "                        print(filtered_text)\n",
    "                    else:\n",
    "                        print(\"‚ö†Ô∏è Tidak ada teks terbaca.\")\n",
    "                else:\n",
    "                    print(\"‚ùå Gagal Tuning (Preprocessing fail)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error pada file ini: {e}\")\n",
    "        else:\n",
    "            print(\"‚ùå Path tidak valid.\")\n",
    "\n",
    "    print(\"\\n‚úÖ SEMUA FILE SELESAI DIPROSES.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_baru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
